{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Image Recognition\n",
    "===\n",
    "\n",
    "This notebook will create a convolutional neural network to classify images in either the mnist or cifar-10 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow and numpy to create the neural network\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Matplotlib to plot info to show our results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# OS to load files and save checkpoints\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data\n",
    "---\n",
    "\n",
    "This code will load the dataset that you'll use to train and test the model.\n",
    "\n",
    "The code provided will load the mnist or cifar data from files, you'll need to add the code that processes it into a format your neural network can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST\n",
    "---\n",
    "\n",
    "Run this cell to load mnist data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST data from tf examples\n",
    "\n",
    "image_height = 28\n",
    "image_width = 28\n",
    "\n",
    "color_channels = 1\n",
    "\n",
    "model_name = \"mnist\"\n",
    "\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "\n",
    "train_data = mnist.train.images\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "\n",
    "eval_data = mnist.test.images\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "category_names = list(map(str, range(10)))\n",
    "\n",
    "# ======================== #\n",
    "# TODO: Process mnist data #\n",
    "# ======================== #\n",
    "# Will Print (55000, 784) List of 55,000 lists of 784 pixels per image\n",
    "print(train_data.shape) \n",
    "\n",
    "# Neural network will need the 784 pixels to be in a multi-dimensional list\n",
    "# -1 infers the shape for proceeding inputs\n",
    "train_data = np.reshape(train_data, (-1, image_height, image_width, color_channels))\n",
    "\n",
    "# Should print (55000, 28, 28, 1)\n",
    "print(train_data.shape)\n",
    "\n",
    "eval_data = np.reshape(eval_data, (-1, image_height, image_width, color_channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-10\n",
    "---\n",
    "\n",
    "Run this cell to load cifar-10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cifar data from file\n",
    "# NOTE each image in CIFAR-10 Data set is 32x32 with 3 colour channels \n",
    "# total of 3072 inputs\n",
    "\n",
    "image_height = 32\n",
    "image_width = 32\n",
    "\n",
    "color_channels = 3\n",
    "\n",
    "model_name = \"cifar\"\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "cifar_path = './cifar-10-data/'\n",
    "\n",
    "\n",
    "\n",
    "# Load the english category names.\n",
    "category_names_bytes = unpickle(cifar_path + 'batches.meta')[b'label_names']\n",
    "category_names = list(map(lambda x: x.decode(\"utf-8\"), category_names_bytes))\n",
    "\n",
    "# ======================== #\n",
    "# TODO: Process Cifar data #\n",
    "# ======================== #\n",
    "\n",
    "# Function that processes data from 0 to 255 TO 0 to 1.0\n",
    "# Data is organized in RGB values i.e. [ r1 , b1 , g1] \n",
    "def process_data(data):\n",
    "    # Converts Array to floats & changes values to 0.0 or 1.0\n",
    "    float_data = np.array(data, dtype=np.float32) / 255.0\n",
    "    \n",
    "    # same as MNIST reshapes data in multi-dimensional to be fed to neural network\n",
    "    reshaped_data = np.reshape(float_data, (-1, color_channels, image_height, image_width))\n",
    "     \n",
    "    # sorts RGB values to show a clearer picture\n",
    "    transposed_data = np.transpose(reshaped_data, [0, 2, 3, 1])\n",
    "    # returns transposed data of image\n",
    "    return transposed_data\n",
    "\n",
    "# =========================================== #\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "train_filename = \"cifar-10-data/train.tfrecords\"\n",
    "\n",
    "if not os.path.isfile(train_filename):\n",
    "    # If training data isn't rfrecorded yet, do so.\n",
    "    \n",
    "    train_data = np.array([])\n",
    "    train_labels = np.array([], dtype=np.int64)\n",
    "    \n",
    "    # Load all the data batches.\n",
    "    for i in range(1,6):\n",
    "        data_batch = unpickle(cifar_path + 'data_batch_' + str(i))\n",
    "        train_data = np.append(train_data, data_batch[b'data'])\n",
    "        train_labels = np.append(train_labels, data_batch[b'labels'])\n",
    "    \n",
    "    writer = tf.python_io.TFRecordWriter(train_filename)\n",
    "    \n",
    "    train_data = process_data(train_data)\n",
    "    \n",
    "    for index in range(len(train_data)):\n",
    "        feature = {'image': _bytes_feature(tf.compat.as_bytes(train_data[index].tostring())),\n",
    "                   'label': _int64_feature(train_labels[index])}\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        \n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    writer.close()\n",
    "    print(\"Training data generated in \" + train_filename)\n",
    "\n",
    "\n",
    "# Load the eval batch.\n",
    "eval_batch = unpickle(cifar_path + 'test_batch')\n",
    "\n",
    "eval_data = eval_batch[b'data']\n",
    "eval_labels = eval_batch[b'labels'] \n",
    "\n",
    "eval_data = process_data(eval_data)\n",
    "\n",
    "# Function to parse a training tfrecord\n",
    "def parse_cifar_record(record):\n",
    "    features = tf.parse_single_example(\n",
    "        record,\n",
    "        features={\n",
    "            'image': tf.FixedLenFeature([], tf.string),\n",
    "            'label': tf.FixedLenFeature([], tf.int64),\n",
    "        })\n",
    "    image = tf.decode_raw(features['image'], tf.float32)\n",
    "    image.set_shape([color_channels * image_height * image_width])\n",
    "    image = tf.reshape(image, [image_height, image_width, color_channels])\n",
    "    label = tf.cast(features['label'], tf.float32)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is processed, you have a few variables for the data itself and info about its shape:\n",
    "\n",
    "### Model Info\n",
    "\n",
    "- **image_height, image_width** - The height and width of the processed images\n",
    "- **color_channels** - the number of color channels in the image. This will be either 1 for grayscale or 3 for rgb.\n",
    "- **model_name** - either \"cifar\" or \"mnist\" - if you need to handle anything differently based on the model, check this variable.\n",
    "- **category_names** - strings for each category name (used to print out labels when testing results)\n",
    "\n",
    "### Training Data\n",
    "\n",
    "- **train_data** - the training data images\n",
    "- **train_labels** - the labels for the training data - the \"answer key\"\n",
    "\n",
    "### Evaluation Data\n",
    "\n",
    "- **eval_data** - Image data for evaluation. A different set of images to test your network's effectiveness.\n",
    "- **eval_labels** - the answer key for evaluation data.\n",
    "\n",
    "Building the Neural Network Model\n",
    "--\n",
    "\n",
    "Next, you'll build a neural network with the following architecture:\n",
    "\n",
    "- An input placeholder that takes one or more images.\n",
    "- 1st Convolutional layer with 32 filters and a kernel size of 5x5 and same padding\n",
    "- 1st Pooling layer with a 2x2 pool size and stride of 2\n",
    "- 2nd Convolutional layer with 64 filters and a kernel size of 5x5 and same padding\n",
    "- 2nd Pooling layer with a 2x2 pool size and stride of 2\n",
    "- Flatten the pooling layer\n",
    "- A fully connected layer with 1024 units\n",
    "- A dropout layer with a rate of 0.4\n",
    "- An output layer with an output size equal to the number of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class declaration\n",
    "class ConvNet:\n",
    "    # Constructor\n",
    "    # This will setup the CNN\n",
    "    def __init__(self, image_height, image_width, channels, num_classes):\n",
    "        # First layer is just for processing the inputs\n",
    "        self.input_layer = tf.placeholder(dtype=tf.float32,\n",
    "                                          shape=[None, image_height, image_width, channels],\n",
    "                                          name=\"inputs\")\n",
    "        # Show the shape of the input layer\n",
    "        print(self.input_layer.shape)\n",
    "        \n",
    "        # Creating the first of the convolution layers\n",
    "        conv_layer_1 = tf.layers.conv2d(self.input_layer, filters=64, kernel_size=[3, 3],\n",
    "                                        padding=\"same\", activation=tf.nn.relu)\n",
    "        print(conv_layer_1.shape)\n",
    "        \n",
    "        # Creating the first pooling layer\n",
    "        pooling_layer_1 = tf.layers.max_pooling2d(conv_layer_1, pool_size=[2, 2], strides=2)\n",
    "        print(pooling_layer_1.shape)\n",
    "        \n",
    "        # Creating the second of the convolution layers\n",
    "        conv_layer_2 = tf.layers.conv2d(pooling_layer_1, filters=128, kernel_size=[3, 3],\n",
    "                                        padding=\"same\", activation=tf.nn.relu)\n",
    "        print(conv_layer_2.shape)\n",
    "        \n",
    "        # Creating the second pooling layer\n",
    "        pooling_layer_2 = tf.layers.max_pooling2d(conv_layer_2, pool_size=[2, 2], strides=2)\n",
    "        print(pooling_layer_2.shape)       \n",
    "        \n",
    "        # Flatten all layers\n",
    "        flattened_pooling = tf.layers.flatten(pooling_layer_2)\n",
    "        \n",
    "        # Make it dense\n",
    "        dense_layer = tf.layers.dense(flattened_pooling, 1024, activation=tf.nn.relu)\n",
    "        print(dense_layer.shape)\n",
    "        \n",
    "        # Add some randomness to the NN\n",
    "        dropout = tf.layers.dropout(dense_layer, rate=0.4, training=True)\n",
    "        print(dropout.shape)\n",
    "        \n",
    "        # Final layer\n",
    "        outputs = tf.layers.dense(dropout, num_classes)\n",
    "        print(outputs.shape)\n",
    "        \n",
    "        self.choice = tf.argmax(outputs, axis=1)\n",
    "        self.probability = tf.nn.softmax(outputs)\n",
    "        \n",
    "        self.labels = tf.placeholder(dtype=tf.float32, name=\"labels\")\n",
    "        self.accuracy, self.accuracy_op = tf.metrics.accuracy(self.labels, self.choice)\n",
    "        \n",
    "        one_hot_labels = tf.one_hot(indices=tf.cast(self.labels, dtype=tf.int32), depth=num_classes)\n",
    "        self.loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits=outputs)\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=5e-2)\n",
    "        self.train_operation = optimizer.minimize(loss=self.loss, global_step=tf.train.get_global_step())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Training Process\n",
    "---\n",
    "\n",
    "The cells below will set up and run the training process.\n",
    "\n",
    "- Set up initial values for batch size, training length.\n",
    "- Process data into batched datasets to feed into the network.\n",
    "- Run through batches of training data, update weights, save checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: initialize variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Performance\n",
    "---\n",
    "\n",
    "These cells will evaluate the performance of your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Display graph of performance over time\n",
    "plt.figure().set_facecolor('white')\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot(performance_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run through the evaluation data set, check accuracy of model\n",
    "with tf.Session() as sess:\n",
    "    checkpoint = tf.train.get_checkpoint_state(path)\n",
    "    saver.restore(sess,checkpoint.model_checkpoint_path)\n",
    "    \n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    for image, label in zip(eval_data, eval_labels):\n",
    "        sess.run(cnn.accuracy_op, feed_dict={cnn.input_layer:[image], cnn.labels:label})\n",
    "    \n",
    "    print(sess.run(cnn.accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get a random set of images and make guesses for each\n",
    "with tf.Session() as sess:\n",
    "    checkpoint = tf.train.get_checkpoint_state(path)\n",
    "    saver.restore(sess,checkpoint.model_checkpoint_path)\n",
    "    \n",
    "    indexes = np.random.choice(len(eval_data), 10, replace=False)\n",
    "    \n",
    "    rows = 5\n",
    "    cols = 2\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5,5))\n",
    "    fig.patch.set_facecolor('white')\n",
    "    image_count = 0\n",
    "    \n",
    "    for idx in indexes:\n",
    "        image_count += 1\n",
    "        sub = plt.subplot(rows,cols,image_count)\n",
    "        img = eval_data[idx]\n",
    "        if model_name == \"mnist\":\n",
    "            img = img.reshape(28, 28)\n",
    "        plt.imshow(img)\n",
    "        guess = sess.run(cnn.choice, feed_dict={cnn.input_layer:[eval_data[idx]]})\n",
    "        if model_name == \"mnist\":\n",
    "            guess_name = str(guess[0])\n",
    "            actual_name = str(eval_labels[idx])\n",
    "        else:\n",
    "            guess_name = category_names[guess[0]]\n",
    "            actual_name = category_names[eval_labels[idx]]\n",
    "        sub.set_title(\"G: \" + guess_name + \" A: \" + actual_name)\n",
    "    plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
